---
title: "index.Rmd"
author: "Lucas Taams"
date: "2023-02-15"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true 
    theme: lumen
    layout: pageWithSidebar
    orientation: rows
    sanitize_text: false
---
```{r, test}
library(tidyverse)
library(spotifyr)
library(plotly)
library(compmus)
library(knitr)
library(gridExtra)
library(dplyr)
library(shiny)
library(rmarkdown)
library(tidymodels)
library(heatmaply)
library(htmltools)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, playlists, echo=FALSE}
old <- get_playlist_audio_features("", "5c80tWKQ1LRPgKqCTEcYKl")
U290s <- get_playlist_audio_features("", "2X6yRUJ8L0fGif3fdAii51")
FirstTime <- get_tidy_audio_analysis("1T6Gh6QOePgmdxpDF1DFx6") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
Mofo <- get_tidy_audio_analysis("6CFk4rAzGaRzoVtjEhcAl9") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
WithWithout <- get_tidy_audio_analysis("5JGEAz15LkPoOtFHttDtVs") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
One <- get_tidy_audio_analysis("3G69vJMWsX6ZohTykad2AU") |> 
  compmus_align(sections, segments) |>                     
  select(sections) |>                                      
  unnest(sections) |>                                      
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "euclidean"              
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "euclidean"              
      )
  )

U290s2 <-
  get_playlist_audio_features("", "2X6yRUJ8L0fGif3fdAii51") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

old2 <-
  get_playlist_audio_features("", "5c80tWKQ1LRPgKqCTEcYKl") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))
```

Introduction
=====================================

**Portfolio for Computational Musicology**

My corpus will consist of several Albums by U2, divided into 2 notable groups: Albums before 1991 (Boy, October, War, The Joshua Tree, Rattle and Hum) and albums in the 90's (Achtung Baby, Zooropa, Pop).

The reason I have chosen for this format is the (quite radical at times) disparity between the genres, stylistic choices and contextual meanings between these periods. After the Joshua Tree (1987) this change already started taking shape, but the culmination started with Achtung Baby (1991). U2 used to be a punk/rock/new wave band, But chose to change radically in the 90's, following in the footsteps of the experimental ideas of Producer and Musician Brian Eno. Eno worked with U2 on the Joshua Tree (amongst other things), but employed a much more aetherial, electronic sound in his own works. This, in combination with the rise of 'dance' and electronic music in the 90's, shaped the stylistic choices made by the band throughout the 90's. With these choices they lost many fans who had been with them since the beginning. I am curious to see how these periods compare, and how we can use spotify to dive into this topic.

A typical track for what I would call the 'early' period is "Sunday Bloody Sunday" (Joshua Tree). It is a punkrock song of protest, perfectly fitting the themes and feel of their (previous) albums. A typical track for the late period would be "Zooropa" (Zooropa), and experimental track that is especially adverse when compared to 'Sunday Bloody Sunday'. Now, there aren't many atypical tracks in the early period, but tracks like 'One' (Achtung Baby) and 'Stay (Faraway, so close)' (Zooropa) are very atypical inbetween their work in the 90's. 

It will be very interesting to discover in what ways the Spotify API can provide an insight into the disparity between the 2 periods, as well as a more in-depth review of some of the outlying tracks in both periods, also taking into consideration the significant advancements made in the field of music production in and around the 90's. 

On a sidenote, I would like to inform the reader that even though I have made a valiant attempt to create a visually pleasable and feasible template for this dashboard, my lack (or rather complete absence) of computing and coding experience has made this a frustrating and time-consuming task. I have therefore decided to focus on the content of the portfolio, rather than the visual layout. I apologise in advance if this makes my portfolio unclear in any way. As I said, I have tried my very best... 

Sidebar {.sidebar}
-------------------------------------

```{r, echo=FALSE}
htmltools::includeHTML ("~/portfolio2023/Spotify playlists.Rhtml")
```


Track-level Features
=====================================

Row
------

### U2 pre-90's

```{r, echo=FALSE}

old |> ggplot(aes(x = acousticness, y = energy, text = track.name)) + 
  geom_point() + geom_smooth() + labs(title = "U2 before the 90's", x = "Acousticness", y = "Energy") + theme(aspect.ratio = 1)
ggplotly(tooltip = c("x", "y", "text"))
```

Row
------

### U2 90's
```{r, echo=FALSE}
U290s |> ggplot(aes(x = acousticness, y = energy, text = track.name)) + 
  geom_point() + geom_smooth() + labs(title = "U2 in the 90's", x = "Acousticness", y = "Energy") + theme(aspect.ratio = 1)
 ggplotly(tooltip = c("x", "y", "text"))

```

Sidebar {.sidebar}
-------------------------------------

*Discussion*

The graph on the left shows the relation between energy and acousticness in the songs by U2 from before 1990 and the graph on the right does the same for the 90's period. This showcases that the experimental phase of U2 in the 90's goes hand in hand with a decrease in overall acousticness, whilst maintaining the energy present in their earlier work. The outlier on the bottom right is a song called 'The First Time'. I have chosen to limit these plots to the songs before 2000, as their 2000 album 'All that you can't leave behind' (featuring smash hit 'Beautiful day') meant a return to their style from the 80's after 'POP' (1997), their most dissapointing album in terms of sales and reviews. 

The reason for the return to their old style after the turn of the century has everything to do with the struggles of the band in the 90's, which came from their will to innovate and 'move with the times' (although I think they just had a bit of an identity crisis). Comparing the pre 1990 and post 1990 period in a computational manner will shed a light on the most extensive differences between the two periods, which I will relate to the consequences this had for the band and their music going forward.

Chroma features
=====================================

### First Time
```{r, echo=FALSE}
FirstTime |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

### Mofo
```{r, echo=FALSE}
Mofo |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

### With or Without you
```{r, echo=FALSE}
WithWithout |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

Sidebar {.sidebar}
-------------------------------------

*Chroma Analysis*

On this page I showcase the chroma features of three different tracks by U2, to delve a bit deeper into the harmonic structure of some of their songs in different periods. I have chosen:

'The First Time' (Key: G# major), an outlier track from the 90s which displays a combination of low energy and high acousticness that is unusual for their music from that period. The chromagram shows high magnitude in the G#, a bit in C (harmonic third), and most explicitly the D# (harmonic 5th), which is logical as D#major is the most prevalent chord in the song, and theres also significant harmonics coming from the root chord G#major. Furthermore it is quite monotone in its harmonic structure, in contrast to the track 'Mofo' on its right, which is from the same period but radically different. 

'Mofo', produced by synthpop producer Mark Ellis (aka Flood) is an eclectic, high energy song which has an acousticness of near zero (understandably). It is very representative of the artistic turn U2 took in the 90's embracing dance and disco whilst leaving the elements that made them famous in the 80's behind. The use of modulating, distorted synths and the fast tempo of the song atrribute to its energy and acousticness rating, but are also reflected in the chromagram which is a bit all over the place, as it struggles with these effects. 

'With or Without You', one of their most iconic songs from the 'Joshua Tree' Album (1987) which is on the lower end of the energy spectrum in comparison to many of the other tracks and displays a low acousticness according to the Spotify API, even though it doesn't exactly feel that way. Synths, the use of reverb and other forms of FX likely contribute to this. This was quite innovative for the time period and was a consequence of the moving and renovating of windmill lane studios in Dublin. This was done explicitly to accomodate the technology and capacity required for the ambitions U2 had with the Joshua Tree album. The chromagram shows that this song has a clear key (D major) and harmonic structure which doesn't fluctuate too much. This makes it an excellent example to be set against 'Mofo'. 


Loudness and Timbre
=====================================

### One 
```{r, echo=FALSE}
One |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic() +
  scale_x_continuous(breaks = c(60, 120, 180, 240, 300))
```

Sidebar {.sidebar}
-------------------------------------

*Loudness and Timbre*

The Cepstogram (or 'Timbregram') on the right showcases the Timbre features of one of U2's most well known songs: 'One' (1991) from the album 'Achtung Baby'. This album showcases the transition between their early work and their experimental phase in the 90's. It also provides the only number 1 hit they score in this period, which ironically is closest to their earlier work as well. 'One' has quite a standard structure: (V-CH-V2-CH2-V3-CH3-B-Ch4-Outtro) but increases in energy exponentially towards the climax where singer Bono exclaims 'Higher! (Baby). This is represented very well in the cepstogram, where timbre feature c01 (loudness) increases in magnitude all the way through to the end.

We also see an increase in magnitude on c05 (Standard pitch deviation). This is likely due to the Edge's (guitarist) riffs. Although they are simple from a musicians perspective, they do create a level of harmonic complexity which causes the increase in magnitude. Around 50sec and 110sec, this guitar makes room for a more staccato use of chords, explaining the slight decrease in magnitude at this point. The Edge uses a fat guitar sound with slight echo and delay, which creates his iconic sound.

The harmonic content (co6) has a low magnitude, which is logical from a musicians perspective (like I mentioned earlier) because many of the harmonic patterns are continuously repeated throughout the song. An explanation as to why the magnitude drops as the song progresses could be that the harmonic content becomes more noisy and muddy as the loudness increases, making unique instruments less able to stand out amongst the rest. 

Many of the disco tracks of the 90's are represented by synth basses and electronic instruments that operate on the low end of the frequency spectrum. The spectral rolloff (c11) and spectral centroid (c07) values indicate that 'One' does not operate in this part of the spectrum too much, meaning the noise and muddiness as indicated by c06 aren't (primarily) caused by this phenomenon. 

Temporal features
=====================================

### Tempogram 'Mofo'
```{r, echo=FALSE}
knitr::include_graphics("/Users/lucastaams/portfolio2023/Mofo tempogram.png")
```

### Tempogram 'Surrender'
```{r, echo=FALSE}
knitr::include_graphics("/Users/lucastaams/portfolio2023/Surrender Tempogram.png")
```

Sidebar {.sidebar}
-------------------------------------

*Temporal comparisons*

For my temporal comparisons I have chosen the 2 tracks with the highest energy values from both periods (according to the scatter plot on the track features page). They are also both over 5 minutes, making them, to an extent, equals in their own time periods.

Although the tempo of both of these tracks is high, it does not exceed the allegretto domain (112-124BPM). This is logical for 'Surrender', which comes from the album 'War' (1983) and still exists within the post-punk/new wave era of the band. Mofo (120BPM), being their highest energy song from the 90's, showcases that they embraced the disco genre (which is characterised by a BPM between 110-135).

One can also see that although the tempo of both tracks is constant, 'Surrender' has a much thicker and more winding line running across the tempogram. This can be attributed to the recording of more live instruments (especially drums and bass). One can conclude that a metronome was most likely used for the recording, although this tempogram shows that when all instruments are actually played and recorded by musicians, the song is more 'alive' and does not adhere to the strict tempo of an electronic beat. 

The BPM line for 'Mofo', however, is as straight as it gets with only mild variations, as I'll explain below.

To go a bit deeper into both songs/tempograms:

*Mofo*

Mofo is based around a sample from the 1970 disco hit "Funky Nassau" by the Bahama Soul Stew. Although the beat and rhythm of the track are very reminiscent of 90's disco, it's the structure of the track which connects it to U2's characteristic rock style. The song tempo is 120 BPM, but shows significant tempo deviations/harmonics towards the middle and ending of the song. At 2:43, the drums completely dissappear and they only pick up again around 3:00, which explains the deviation there. Towards the end of the song something interesting happens, as the guitar starts playing 16th notes off-sync to the beat, creating what I like to call a 'rotary spacious feeling', almost like a helicopter (this is caused by offset delays on the guitar). I find it very interesting that the spectogram recognises this as a  rhythmical element.

*Surrender* 

The song tempo is a pretty steady 117 BPM but the tempogram shows one deviation between 2:35 - 2:50, which is when the snaredrum drops out and a break of sorts occurs, disrupting the pattern displayed in the drums throughout the rest of the song. Although the tempo doesn't change this does throw off the computation, as can be seen by the vertical line around the middle of the tempogram.


Classification and Clustering
=====================================

### Heatmap U2 before 1990

```{r, echo=FALSE, cache = TRUE}
old2_unique <- old2 %>%
  mutate(track.name = make.names(track.name, unique = TRUE)) %>%
  distinct(track.name, .keep_all = TRUE)

old2_juice <- recipe(
  track.name ~
    danceability +
    energy +
    loudness +
    acousticness +
    instrumentalness +
    liveness +
    valence +
    tempo,
  data = old2_unique
) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  step_range(all_predictors()) |>
  prep() |>
  juice() |>
  column_to_rownames("track.name")

heatmaply(old2_juice,
           hclustfun = hclust,
           hclust_method = "average",
           dist_method = "euclidean",
           showticklabels = TRUE,    
           fontsize_row = 8,         
           fontsize_col = 8,  
)
```
### Heatmap U2 90's

```{r, echo=FALSE, cache = TRUE}
U290s2_unique <- U290s2 %>%
  mutate(track.name = make.names(track.name, unique = TRUE)) %>%
  distinct(track.name, .keep_all = TRUE)

U290s2_juice <- recipe(
  track.name ~
    danceability +
    energy +
    loudness +
    acousticness +
    instrumentalness +
    liveness +
    valence +
    tempo,
  data = U290s2_unique
) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  step_range(all_predictors()) |>
  prep() |>
  juice() |>
  column_to_rownames("track.name")

heatmaply(U290s2_juice,
          hclustfun = hclust,
          hclust_method = "average",
          dist_method = "euclidean",
          showticklabels = TRUE,    
          fontsize_row = 8,         
          fontsize_col = 8, 
          )
```

*CLustering Heatmaps*

The interactive heatmaps on the right side show both the playlists within my corpus clustered together based on some of the Spotify API's track feature classifications. 

The left heatmap showcases the playlist of songs by U2 before 1990. When listening to the songs from top to bottom, the intensity and energy of the songs increases. Songs like 'Freedom for my people' (just 1 guitar) and 'October' (just a piano) are nicely clustered together, whilst the more adventurous, 'heavy' recordings are grouped at the bottom. 

For the heatmap on the right, the songs are ordered in a similar manner. Here we find the most energetic and 'disco-like' songs at the top, and the more low-energy acoustic songs at the bottom. 


Discussion/Conclusion
=====================================

### **DISCUSSION**

In this portfolio I have used several track level analyses to showcase the differences between the two time periods. To do this I used some of the songs which lie at the extremes of what one would call 'typical' songs for the period. Taking into account the decline in popularity of U2 in the 90's, it is clear that this has to do with the high contrast between the two periods in terms of stylistic choices, energy and acousticness, as well as timbre features. 

The timbre analysis of 'One' shows that it is not a typical track for the 90's disco-like style of U2 and might also explain why it is that 'One' became such a smash hit, in a period where the band was struggling with its identity (ironic, when you take the lyrics of 'One' into consideration).

I always felt that in their 90's albums, U2 lost their ability to connect with me on a deeper level. Their music became shallow, felt overproduced and became more and more abstract. The tempograms show very clearly the disparity in philosophy between the two periods. Before the 90's the music was 'alive'. It lived and breathed and preached. This was lost in their later music, which they luckily realised when the turn of the century came about.

All in allI think the comparison between the 2 periods was quite interesting and useful, and has helped me understand the intricacies of the separation between the 2 periods. Now not only as a sense of feeling and intuition, but also grounded in computational analysis.

### **IN CONCLUSION**

When I started this project I already had a clear image in my mind of the differences between the two time periods in U2's career, mostly based on my own listening experience and previous research I have done in regards to the band (I analysed some of their songs and recording techniques for a conservatory assignment, for example). I soon realised that in analysing on both track and corpus level I was looking to confirm my own premonitions. It was very interesting to see how those premonitions sometimes diverted from the Spotify API, although I also realised that my personal knowledge of the music kickstarted (at times) a sense of disagreeableness. I would be delighted to learn more about the algorithm behind the Spotify API, to see how it comes to certain conclusions. It seems, however, that this is just as likely as finding out what is on the inside of a supermassive black hole. Alas, I digress.

Lastly, I'd like to convey that working with R studio to analyse Spotify's API has been a teachable (and often humbling) experience, definitely not without its ups and downs. It is very rewarding to see a piece of code work after (sometimes) hours of struggling. There are countless more avenues to explore when it comes to computational analysis, so I feel like there's an opportunity for me to spend many more hours wrestling with this. Thank you for reading my portfolio!

*bibliograpy*

Spotify (2023)

London Sound Academy. https://www.londonsoundacademy.com/blog/list-of-electronic-dance-music-genres#:~:text=The%20BPM%20of%20Disco%20can,between%20110%20and%20135%20BPM. 2023. 

U2. https://www.u2.com/. 2023.

Sidebar {.sidebar} 
=====================================

